# OTTO Training Configuration

# Model Architecture
model:
  n_layer: 6
  n_head: 6
  n_embd: 768
  dropout: 0.1
  bias: true
  block_size: 4096
  vocab_size: null  # Auto-detected from tokenizer

# Training Parameters
training:
  max_iters: 20000
  batch_size: 1
  learning_rate: 0.0003
  warmup_steps: 2000
  min_lr: 0.00001
  eval_iters: 500
  gradient_accumulation_steps: 64

# Data Processing
data:
  train_split: 0.9
  min_doc_length: 50
  max_doc_length: null
  tokenizer: "gpt2"

# Paths
paths:
  upload_dir: null  # Uses default if null
  training_data_dir: "training_data"
  model_output_dir: "model_outputs"

# System
system:
  max_file_size: 524288000  # 500MB
  device: null  # Auto-detect
  dtype: null   # Auto-detect